#Προσθήκη όλων των απαραίτητων πακέτων δηλαδή libraries, modules, frameworks (βιβλιοθήκες, ενότητες, πλαίσια) ή μερος αυτών
#για να μπορέσει να εκτελεστεί ο κώδικας. Κάποια πακέτα εισάγονται ολόκληρα απλά με την εντολή "import όνομα_επιθυμητού_πακέτου".
#Σε άλλες περιπτώσεις εισάγονται μέρη αυτών που θα χρειαστούν ή κάποιες functions, methods τους. Για την εισαγωγή ενός
#μόνο μέρους του πακέτου χρησιμοποιείται η σύνταξη "from όνομα_επιθυμητού_πακέτου import όνομα_επιθυμητού_μέρους_του". Επίσης
#με την προσθήκη της εντολής "as επιθυμητό_νέο_όνομα" δίπλα απο την εντολή εισαγωγής κάποιου πακέτου ή μερους αυτού, δίνεται η
#δυνατότητα στον κώδικα να απευθύνεται σε αυτό με ένα νέο όνομα, συνήθως πιο σαφές, απλό και σύντομο.

#Το "tensorflow" είναι ένα framework ανοικτού κώδικα (open-source code) όπου η βιβλιοθήκη του περιέχει εντολές με σκοπό τη
#δημιουργία και εκπαίδευση μοντέλων μηχανικής μάθησης (machine learning models). Επίσης όταν το "tensorflow" εισάγεται, του
#δίνεται το ψευδώνυμο "tf" για να καλείται μέσα στον κώδικα με μεγαλύτερη ευκολία.
import tensorflow as tf

#Εισαγωγή της συνάρτησης "preprocess_input" από το "tensorflow.keras.applications.mobilenet_v2" module. Η συνάρτηση αυτή
#προεπεξεργάζεται τις εισαγόμενες εικόνες και τις προετοιμάζει με βάση την αρχιτεκτονική του μοντέλου MobileNetV2 που
#αποτελεί το συνελικτικό νευρωνικό δίκτυο του μοντέλου που θα εκπαιδευτεί.
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

#Εισαγωγή της συνάρτησης "img_to_array" από το "tensorflow.keras.preprocessing.image" module. Η συνάρτηση αυτή, μετατρέπει
#μία εικόνα σε διάνυσμα της βιβλιοθήκης NumPy έτσι ώστε αυτή να μπορεί να υποβληθεί σε επεξεργασία από μοντέλα μηχανικής
#εκμάθησης.
from tensorflow.keras.preprocessing.image import img_to_array

#Εισαγωγή της κλάσης "VideoStream" από το "imutils.video" module. Η κλάση αυτή παρέχει μία απλοποιημένη διεπαφή για πρόσβαση
#σε ροές βίντεο από διάφορες πηγές, όπως web κάμερες ή αρχεία βίντεο.
from imutils.video import VideoStream

#Εισαγωγή της βιβλιοθήκης "numpy" με το ψευδώνυμο "np" που χρησιμεύει για αριθμητικούς υπολογισμούς στην Python. Επίσης
#παρέχει υποστήριξη για μεγάλους πολυδιάστατους πίνακες ή πίνακες διανυσμάτων, αφού περιέχει μία συλλογή μαθηματικών
#συναρτήσεων για την αποτελεσματική επεξεργασία τους.
import numpy as np

#To "imutils" είναι ένα module που περιέχει συναρτήσεις για την διευκόλυνση της χρήσης της βιβλιοθήκης OpenCV (Open Source
#Computer Vision). Κάποιες από τις λειτουργίες των συναρτήσεων αυτών είναι η αλλαγή μεγέθους των εικόνων και η περιστροφή τους.
import imutils

#Το "cv2" είναι ένα module που ανήκει στην βιβλιοθήκη ανοικτού κώδικα OpenCV η οποία χρησιμοποιείται ευρέως για θέματα
#μηχανικής όρασης (computer vision) και μηχανικής εκμάθησης (machine learning).
import cv2


#									"""Μέρος 1ο - Συνάρτηση για την ανίχνευση μάσκας"""

#Δημιουργία της συνάρτησης, που όταν καλείται απο τον κύριο κώδικα, λαμβάνει το στιγμιότυπο/την εικόνα του βίντεο εκείνης
#της δεδομένης στιγμής και το επεξεργάζεται για να επιστρέψει ξανά στον κύριο κώδικα κάποιες πληροφορίες. Αρχικά, όταν καλείται
#δέχεται ως ορίσματα την εικόνα από το βίντεο, το μοντέλο εντοπισμού ανθρώπινου προσώπου και το μοντέλο εντοπισμού μάσκας.
#Έπειτα γίνονται κάποιες επεξεργασίες πάνω στην εικόνα για να είναι συμβατή με τα δύο παραπάνω μοντέλα που αναφέρθηκαν και
#γίνεται πρώτα ο εντοπισμός προσώπων σε αυτή. Το πρώτο μοντέλο ελέγχει την πιθανότητα ύπαρξης κάποιου προσώπου ή προσώπων
#και αν υπάρχει τότε αποθηκεύει αυτές τις πιθανότητες στην μεταβλητή "detections". Έπειτα γίνεται σύγκριση αυτών των πιθανοτήτων
#με τον αριθμό 0.5, δηλαδή το 50%, όπου αν αυτές είναι μεγαλύτερες από αυτόν τότε θεωρείται ότι βρέθηκε πρόσωπο, αλλιώς
#θεωρείται ότι το πρόγραμμα δεν βρήκε πρόσωπο και απλά ανίχνευσε κάτι παρόμοιο με αυτό. Για τα πρόσωπα που εντοπίστηκαν
#υπολογίζονται οι συντεταγμένες τους πάνω στο στιγμιότυπο και δημιουργείται για κάθε πρόσωπο μία νέα εικόνα μόνο με αυτό,
#η οποία δέχεται κάποιες επεξεργασίες. Οι επεξεργασίες αυτές είναι αρχικά η μετατροπή της από μορφή BGR (Blue Green Red)
#σε RGB (Red Blue Green), αλλαγή των διαστάσεων σε 224x224, μετατροπή σε διάνυσμα και κάποιες άλλες ειδικές επεξεργασίες
#από την μέθοδο "preprocess_input". Όλες αυτές οι επεξεργασίες γίνονται για να είναι συμβατή η εικόνα κατά την εισαγωγή
#της στο μοντέλο ανίχνευσης μάσκας. Πέρα από την εικόνα προσώπου υπολογίζονται και οι συντεταγμένες που θα τοποθετηθεί
#αργότερα το παραλληλόγραμμο γύρω από το πρόσωπο του ανθρώπου που εντοπίστηκε. Στη συνέχεια γίνεται ο έλεγχος ύπαρξης μάσκας
#ή όχι με βάση την εικόνα προσώπου και τα αποτελέσματα που είναι σε μορφή πιθανοτήτων από το 0 έως το 1 αποθηκεύονται στη
#λίστα "preds". Για κάθε εικόνα προσώπου αποθηκεύονται δύο πιθανότητες στη λίστα "preds", μία για την ύπαρξη μάσκας και μία
#για την μη ύπαρξη μάσκας. Τέλος, τα αποτελέσματα αυτά μαζί με τις συντεταγμένες του παραλληλογράμμου, επιστρέφονται στον
#κύριο κώδικα για την περαιτέρω επεξεργασία τους.

#Με το "def" γίνεται ορισμός της συνάρτησης όπου ακριβώς δίπλα του ακολουθεί το όνομα που της δόθηκε, δηλαδή το
#"detect_and_predict_mask". Αμέσως μετά το όνομα, μέσα σε παρενθέσεις, δηλώνονται τα ορίσματα που θα δεχτεί η συνάρτηση
#από τον κύριο κώδικα. Τα ορίσματα αυτά είναι ένα στιγμιότυπο (frame), το μοντέλο ανίχνευσης προσώπου (faceNet) και το
#μοντέλο ανίχνευσης μάσκας (maskNet).
def detect_and_predict_mask(frame, faceNet, maskNet):

#Το χαρακτηριστικό (attribute) ".shape" επιστρέφει πληροφορίες σχετικά με το "frame" πάνω στο οποίο εκτελείται. Με το
#slicing "[:2]" στη λίστα δίνεται εντολή να επιστραφούν μόνο οι πληροφορίες σχετικά με το ύψος και το πλάτος
#του frame. Αυτά αποθηκεύονται σε ένα tuple (πλειάδα) που περιέχει τις μεταβλητές "h" και "w" τα οποία αντιστοιχούν στο
#ύψος και το πλάτος.
	(h, w) = frame.shape[:2]

#Δημιουργία ενός "blob" (Binary Large Object) που θα περιέχει πληροφορίες σχετικά με το "frame"  χρησιμοποιώντας τη
#συνάρτηση "cv2.dnn.blobFromImage" της βιβλιοθήκης OpenCV. Ειδικότερα, γίνεται προεπεξεργασία του "frame" για είσοδο
#στο μοντέλο ανίχνευσης προσώπου δίνοντας στη συνάρτηση κάποιες προδιαγραφές ως ορίσματα. Το πρώτο όρισμα  είναι το
#ίδιο το "frame", το δεύτερο είναι η τιμή 1 που αντιπροσωπεύει στη συγκεκριμένη περίπτωση τη μη σμίκρινση ή μεγέθυνση
#του "frame", το τρίτο είναι οι νέες διαστάσεις που θα πάρει το "frame", δηλαδή 224x224 και το τέταρτο αντιπροσωπεύει
#τις μέσες τιμές pixel που αφαιρούνται από την εικόνα. Σε αυτήν την περίπτωση, το "(104.0, 177.0, 123.0)" αντιστοιχεί
#στις μέσες τιμές για τα κανάλια κόκκινο, πράσινο και μπλε. Το αντικείμενο "blob" που θα δημιουργηθεί θα είναι τεσσάρων
#διαστάσεων όπου η πρώτη είναι η εικόνα που περιέχει, άρα ένα αφου του εισάγουμε μόνο ένα frame. Η δεύτερη περιέχει τα
#τρία κανάλια χρώματος που έχει το "frame" και τα αναγνωρίζει ως BGR (Blue Green Red). Η τρίτη περιέχει το ύψος, δηλαδή
#224 και η τέταρτη το πλάτος όπου και αυτό είναι 224.
	blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224), (104.0, 177.0, 123.0))

#Εισαγωγή του "blob" στο μοντέλο ανίχνευσης προσώπου με την εντολή ".setInput()".
	faceNet.setInput(blob)

#Επεξεργασία του "blob" και ανίχνευση πιθανών προσώπων. Τα αποτελέσματα ανίχνευσης αποθηκεύονται στο διάνυσμα "detections"
#ως πιθανότητες απο το 0 έως το 1.
	detections = faceNet.forward()

#Δημιουργία κενής λίστας στην οποία θα αποθηκευτούν οι εικόνες των προσώπων που μπορεί να βρέθηκαν.
	faces = []

#Δημιουργία κενής λίστας στην οποία θα αποθηκευτούν οι συντεταγμένες των παραλληλογράμμων που θα τοποθετηθούν γύρω
#από τα πρόσωπα που μπορεί να βρέθηκαν.
	locs = []

#Δημιουργία κενής λίστας στην οποία θα αποθηκευτούν οι προβλέψεις για το αν εντοπίστηκε μάσκα ή όχι στα πρόσωπα που
#μπορεί να βρέθηκαν.
	preds = []

#Δημιουργία βρόγχου επανάληψης "for" όπου η μεταβλητή "i" θα παίρνει με τη σειρά τις τιμές από 0 έως τον αριθμό του συνόλου
#των προσώπων που πιθανά βρέθηκαν. Το "range" ορίζει τις τιμές που θα πάρει το "i", δηλαδή απο 0 έως "detections.shape[2]" με
#βήμα 1. Το "detection.shape[2]" επιστρέφει τον αριθμό των προσώπων που πιθανά βρέθηκαν, όπου αυτός ο αριθμός βρίσκεται
#συγκεκριμένα αποθηκευμένος στην τρίτη διάσταση του "detections". Η πρόσβαση στην τρίτη διάσταση αυτή γίνεται με τη χρήση
#του ".shape[2]" όπου το όρισμα "2" αντιστοιχεί στην τρίτη διάσταση, αφού στη γλώσσα προγραμματισμού Python οι δείκτες μίας
#λίστας ξεκινούν απο το 0 και όχι το 1.
	for i in range(0, detections.shape[2]):

#Αποθήκευση της πιθανότητας (confidence score) που περιέχει η νούμερο "i" πρόβλεψη ανίχνευσης προσώπου στη μεταβλητή
#"confidence". Συγκεκριμένα για την αναζήτηση της αποθηκευμένης αυτής πιθανότητας εκτελείται το "detections[0, 0, i, 2]"
#όπου το πρώτο "0" σημαίνει ότι θέλουμε την πρόβλεψη από την πρώτη εικόνα, άρα και τη μοναδική έτσι κι αλλιως αφού
#μόνο πάνω στο "frame" έγιναν προβλέψεις. Το δεύτερο "0" αντιπροσωπεύει ποιας κλάσης την πιθανότητα θέλουμε, αλλά αφού
#μόνο μια κλάση υπάρχει και αυτή είναι το ανθρώπινο πρόσωπο χρησιμοποιείται το "0" που αντιστοιχεί στην πρώτη κλάση.
#Το "i" αντιστοιχεί σε μία από τις προβλέψεις. Το "2" είναι ο δείκτης που περιέχει την πιθανότητα που χρειάζεται να
#αποθηκευτεί στο "confidence".
		confidence = detections[0, 0, i, 2]

#Έλεγχος του "confidence" εάν είναι μεγαλύτερο απο 0.5 δηλαδή 50% πιθανότητα. Εάν είναι, τότε σημαίνει ότι η
#συγκεκριμένη πρόβλεψη είναι αληθής και υπάρχει πρόσωπο στο "frame", οπότε το πρόγραμμα θα συνεχίσει μέσα στο "if".
#Ο κώδικας μέσα στο "if" πραγματοποιεί εύρεση των συντεταγμένων του παραλληλογράμου που θα τοποθετηθεί γύρω από
#το πρόσωπο και δημιουργεί μία νέα εικόνα με το πρόσωπο που βρέθηκε.
		if confidence > 0.5:

#Γίνεται αποθήκευση των συντεταγμένων του νοητού παραλληλογράμμου, γύρω απο το πρόσωπο που εντοπίστηκε, οι οποίες
#είναι αποθηκευμένες στην τέταρτη διάσταση του "detections" με δείκτες 3, 4, 5, 6 αφού το slicing του διανύσματος
#ορίζεται ως "3:7". Επίσης αυτές οι συντεταγμένες πολλαπλασιάζονται με ένα διάνυσμα που περιέχει τις διαστάσεις
#του "frame" για να προσαρμοστούν ως προς το μέγεθός του.
			box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])

#Οι τέσσερις νέες συντεταγμένες που αποθηκεύτηκαν στο "box" μετατρέπονται αρχικά σε ακέραιες (integers) τιμές
#μέσω της μεθόδου ".astype("int")" και έπειτα αποθηκεύονται σε ένα "tuple" και ειδικότερα η κάθε μία σε μία
#αντίστοιχη μεταβλητή.
			(startX, startY, endX, endY) = box.astype("int")

#Επειδή υπάρχει η περίπτωση, θεωρητικά, οι συντεταγμένες να έχουν τιμές εκτός της πραγματικής εικόνας που θα
#εμφανιστούν, γίνεται προσαρμογή τους να μην ξεπερνάνε τα όρια της εικόνας. Οπότε αρχικά, για τις συντεταγμένες
#της πάνω αριστερά γωνίας του νοητού παραλληλογράμου υπολογίζεται η νέα τιμή τους, βρίσκοντας την μέγιστη τιμή
#μεταξύ του 0 και της πραγματικής τους τιμής. Εάν δηλαδή η πραγματική τους τιμή είναι αρνητική, αυτή αναγκαστικά
#θα μετατραπεί σε 0 για να ξεκινήσει να φαίνεται το παραλληλόγραμμο από την κάτω αριστερή γωνία του "frame".
			(startX, startY) = (max(0, startX), max(0, startY))

#Αντίστοιχα εδώ, υπολογίζονται οι νέες τιμές της κάτω δεξιά γωνίας όπου βρίσκεται η μέγιστη τιμή μεταξύ των
#πραγματικών τιμών των συντεταγμένων "endX", "endY" και των ορίων του πλάτους ή του ύψους του "frame" αντίστοιχα
#-1. Το μείον ένα χρειάζεται επειδή το ανώτατο όριο της εικόνας είτε στο πλάτος είτε στο ύψος δεν είναι το 224
#αλλά το 223 λόγω του προγραμματισμού σε γλώσσα Python. Αυτό μπορεί να γίνει πιο ξεκάθαρο αν σκεφτεί κανείς
#πως στην πάνω εντολή τα όρια προσαρμόζονται από το σημείο 0 και όχι το 1 άρα τα όρια είναι 0-223 και όχι 1-224.
			(endX, endY) = (min(w - 1, endX), min(h - 1, endY))

#Εδώ γίνεται εξαγωγή ενός κομματιού του "frame" και συγκεκριμένα αυτού που περιέχει το πρόσωπο που εντοπίστηκε.
#Οι συντεταγμένες που υπολογίστηκαν προηγουμένως συμβάλλουν σε αυτή τη διαδικασία και η νέα εικόνα του προσώπου
#αποθηκεύεται στη μεταβλητή "face".
			face = frame[startY:endY, startX:endX]

#Επειδή το "frame" ήταν της μορφής BGR έτσι και το "face" δημιουργήθηκε ως BGR. Επειδή όμως αυτή η μορφή εικόνας
#δεν είναι συμβατή με αυτή που θα πρέπει να ελέγξει το μοντέλο ανίχνευσης μάσκας, πρέπει να αλλάξει και να μετατραπεί
#σε μορφή RGB. Για αυτό αναλαμβάνει η συνάρτηση ".cvtColor()" που δέχεται ως πρώτο όρισμα την εικόνα "face"
#και σαν δεύτερο όρισμα την μορφή που πρέπει να γίνει η μετατροπή.
			face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)

#Προσαρμογή της εικόνας "face" στις διαστάσεις 224 x 224, διότι το μοντέλο ανίχνευσης μάσκας έχει εκπαιδευτεί
#για να δέχεται εικόνες αυτών των συγκεκριμένων διαστάσεων. Αυτό επιτυγχάνεται με την συνάρτηση ".resize()"
#της βιβλιοθήκης OpenCV η οποία δέχεται ως ορίσματα την εικόνα "face" και τις διαστάσεις προσαρμογής.
			face = cv2.resize(face, (224, 224))

#Μετατροπή της εικόνας "face" σε μορφή διανύσματος με τη χρήση της συνάρτησης "img_to_array()" από το
#"tensorflow.keras.preprocessing.image" module. Αυτή η μετατροπή είναι απαράιτητη για την προετοιμασία
#του "face" για περαιτέρω επεξεργασία από το μοντέλο ανίχνευσης μάσκας.
			face = img_to_array(face)

#Με τη συνάρτηση "preprocess_input()" από το "tensorflow.keras.applications.mobilenet_v2" module γίνονται
#κάποιες τελικές μετατροπές στο "face" για να μπορεί να είναι συμβατό με την αρχιτεκτονική της "mobilenet_v2"
#που είναι αυτή που χρησιμοποιήθηκε για την κατασκευή του μοντέλου ανίχνευσης μάσκας.
			face = preprocess_input(face)

#Προσθήκη του διανύσματος "face" στη λίστα "faces" με την συνάρτηση ".append()" που προσθέτει ένα νέο διάνυσμα
#κάθε φορά στο τέλος της λίστας.
			faces.append(face)

#Προσθήκη στη λίστα "locs", με τη βοήθεια πάλι της εντολής ".append()", των συντεταγμένων του παραλληλογράμου
#που θα σχεδιαστεί αργότερα γύρω από το πρόσωπο που αντιστοιχεί στο "face" που αποθηκέυτηκε προηγουμένως στην
#λίστα "faces".
			locs.append((startX, startY, endX, endY))

#Έλεγχος με τη συνθήκη "if" εάν υπάρχει έστω ένα εντοπισμένο πρόσωπο στο "frame". Εάν υπάρχει, τότε ο κώδικας συνεχίζει
#μέσα στο "if" όπου ξεκινάει η ανίχνευση μάσκας. Αν δεν υπάρχει, τότε ο κώδικας επιστρέφει τις κενές λίστες "locs" και
#"preds" στον κύριο κώδικα. Στη συνθήκη "if" ελέγχεται ουσιαστικά το μήκος της λίστας "faces" εάν είναι μεγαλύτερο
#του μηδενός, αφού εάν υπήρχε έστω και ένα "face" μέσα του, το μήκος θα ήταν τουλάχιστον 1. Ο υπολογισμός του μήκους
#της λίστας γίνεται με την εντολή "len()".
	if len(faces) > 0:

#Δημιουργία βρόγχου επανάληψης "for" που θα ελέγξει ξεχωριστά όλα τα πρόσωπα που εντοπίστηκαν και βρίσκονται
#μέσα στην λίστα "faces".
		for face in faces:

#Προσθήκη στο "face" μίας επιπλέον διάστασης στην αρχή των άλλων διαστάσεων που θα αντιπροσωπεύει τον αριθμό
#των εικόνων που περιέχει αυτό το διάνυσμα. Αυτή η μετατροπή γίνεται μόνο για λόγους συμβατότητας με το μοντέλο
#ανίχνευσης μάσκας επειδή είναι σχεδιασμένο να δέχεται διανύσματα τεσσάρων διαστάσεων, ενώ το "face" έχει τρείς.
#Για παράδειγμα εάν το "face" έχει τη μορφή (224, 224, 3) τότε μετά την μετατροπή θα μοιάζει έτσι (1, 224, 224, 3).
#Για την προσθήκη της νέας διάστασης χρησιμοποιείται η εντολή "np.expand_dims()" της βιβλιοθήκης "numpy"
#που δέχεται ως πρώτο όρισμα το "face" και ως δεύτερο την τοποθεσία της νέας διάστασης με δείκτη "0" δηλαδή
#στην πρώτη θέση.
			face = np.expand_dims(face, axis=0)

#Με την εκτέλεση της εντολής ".set_tensor()" πάνω στο μοντέλο ανίχνευσης μάσκας ή "maskNet" γίνεται ανάθεση
#του διανύσματος "face" στον τανυστή εισόδου του μοντέλου. Πιο συγκεκριμένα, το μοντέλο θα δεχτεί στην είσοδό του
#το "face". Το πρώτο όρισμα που δέχεται η εντολή είναι το "input_details[0]['index']" το οποίο είναι μία λίστα
#λεξικών (Python Dictionaries) που περιέχουν πληροφορίες σχετικά με τους τανυστές εισόδου του μοντέλου. Ειδικότερα,
#με τον δείκτη "0" παρέχονται πληροφορίες από το λεξικό για τον πρώτο τανυστή εισόδου. Το "'index'" είναι υπεύθυνο
#για την αναγνώριση και προετοιμασία του συγκεκριμένου τανυστή εισόδου. Το δεύτερο όρισμα είναι το διάνυσμα
#"face".
			maskNet.set_tensor(input_details[0]['index'], face)

#Με την εντολή ".invoke()" ξεκινά η διαδικασία πρόβλεψης με βάση το διάνυσμα "face" που περιέχει το πρόσωπο
#κάποιου ανθρώπου. Τα αποτελέσματα αποθηκεύονται στο μοντέλο.
			maskNet.invoke()

#Me την εντολή ".get_tensor()" πάνω στο "maskNet" λαμβάνονται τα αποτελέσματα, δηλαδή οι προβλέψεις από τον
#τανυστή εξόδου του μοντέλου. Αυτά τα αποτελέσματα αποθηκεύονται στη μεταβλητή "pred" και περιέχουν την πιθανότητα
#για την ύπαρξη μάσκας άλλα και την πιθανότητα για την μη ύπαρξη μάσκας. Το ".get_tensor()" δέχεται ένα μόνο
#όρισμα το οποίο είναι το "output_details[0]['index']" που παρομοίως με τον τανυστή εισόδου παρέχει πληροφορίες
#και προετοιμάζει τον πρώτο τανυστή εξόδου.
			pred = maskNet.get_tensor(output_details[0]['index'])

#Η πρόβλεψη "pred" που έγινε προστίθεται στη λίστα "preds" που θα περιέχει όλες τις προβλέψεις για όλα τα πρόσωπα
#που εντοπίστηκαν.
			preds.append(pred)

#Τέλος, γίνεται επιστροφή στον κύριο κώδικα των "locs" και "preds" ως tuple για την τελική επεξεργασία τους και εμφάνιση
#των αποτελεσμάτων σε live video stream.
	return (locs, preds)


#		"""Μέρος 2ο - Κύριος κώδικας ενεργοποίησης video stream και απεικόνηση των αποτελεσμάτων σε παράθυρο"""


#Αποθήκευση της τοποθεσίας του αρχείου "deploy.prototxt" ως raw string  στη μεταβλητή "prototxtPath". Το "deploy.prototxt"
#είναι το πρώτο από τα δύο αρχεία που αποτελούν το μοντέλο ανίχνευσης προσώπου και περιέχει πληροφορίες σχετικά με την
#αρχιτεκτονική του, τις παραμέτρους του, τα επίπεδά του και τη σύνδεση μεταξύ αυτών. To μοντέλο που χρησιμοποιείται
#ονομάζεται Single Shot MultiBox Detector (SSD) και έχει σχεδιαστεί με βάση την αρχιτεκτονική του "MobileNetV1".
prototxtPath = r"face_detector_model/deploy.prototxt"

#Αποθήκευση της τοποθεσίας του δεύτερου αρχείου του μοντέλου ανίχνευσης προσώπου "res10_300x300_ssd_iter_140000.caffemodel"
#ως raw string στη μεταβλητή "weightsPath". Αυτό το αρχείο περιέχει πληροφορίες σχετικά με τα βάρη του μοντέλου και τις
#εκπαιδευμένες παραμέτρους του. Τα βάρη αντιπροσωπεύουν τις γνώσεις του μοντέλου για την καλή αναγνώριση διάφορων
#χαρακτηριστικών σε εικόνες. Αυτά έχουν διαμορφωθεί μετά από εκπαίδευση του μοντέλου πάνω σε ένα τεράστιο σύνολο δεδομένων
#σχετικά με την αναγνώριση προσώπων.
weightsPath = r"face_detector_model/res10_300x300_ssd_iter_140000.caffemodel"

#Με την εντολή "cv2.dnn.readNet()" της βιβλιοθήκης "openCV" γίνεται φόρτωση του μοντέλου αναγνώρισης προσώπου στο αντικείμενο
#"faceNet". Η εντολή δέχεται ως ορίσματα τις δύο τοποθεσίες των αρχείων που προαναφέρθηκαν, ώστε αυτά να δημιουργήσουν το
#μοντέλο μετά την ένωση και την κατάλληλη επεξεργασία τους.
faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)

#Αποθήκευση της τοποθεσίας του αρχείου "mask_detection_model_optim.tflite" ως raw string στη μεταβλητή "mask_string". Το
#αρχείο αυτό αντιπροσωπεύει το μοντέλο που εκπαιδεύτηκε για την ανίχνευση μάσκας και έχει τη μορφή ".tflite".
mask_string = r"mask_detection_model_optim.tflite"

#Φόρτωση του αρχείου "mask_detection_model_optim.tflite" και δημιουργία του μοντέλου ανίχνευσης μάσκας με όνομα αντικειμένου
#"maskNet". Η δημιουργία του μοντέλου οφείλεται στην εντολή "tf.lite.Interpreter()" της βιβλιοθήκης "tensorflow" και συγκεκριμένα
#του μέρους του που ονομάζεται "tensorflow lite". Η εντολή αυτή δέχεται ως όρισμα την τοποθεσία του αρχείου του μοντέλου
#στον υπολογιστή δηλαδή το "mask_string". Η σύνταξη του ορίσματος είναι η εξής "model_path = mask_string".
maskNet = tf.lite.Interpreter(model_path = mask_string)

#Η εντολή ".allocate_tensors()" είναι απαραίτητη πριν από οποιαδήποτε χρήση του μοντέλου στον κώδικα διότι κατανέμει στη
#μνήμη τους τανυστές εισόδου και εξόδου. Μετά από αυτήν την εντολή το μοντέλο "maskNet" είναι έτοιμο να δεχτεί εισόδους
#και να παρέχει εξόδους.
maskNet.allocate_tensors()

#Η εντολή ".get_input_details()" παρέχει πληροφορίες σχετικά με τους τανυστές εισόδου του μοντέλου τις οποίες αποθηκεύει
#στο αντικείμενο "input_details". Πιο συγκεκριμένα, θα αποθηκευτεί μία λίστα απο dictionaries όπου κάθε dictionary αντιστοιχεί
#σε ένα τανυστή εισόδου παρέχοντας πληροφορίες, όπως όνομα και τύπος δεδομένων.
input_details = maskNet.get_input_details()

#Η εντολή ".get_output_details()" παρέχει πληροφορίες σχετικά με τους τανυστές εξόδου του μοντέλου τις οποίες αποθηκεύει
#στο αντικείμενο "output_details". Όπως και για τους τανυστές εισόδου αντίστοιχα θα αποθηκεύεται μία λίστα από
#dictionaries όπου κάθε dictionary αντιστοιχεί σε έναν τανυστή εξόδου.
output_details = maskNet.get_output_details()

#Εκτύπωση ενημερωτικού μηνύματος στην οθόνη.
print("[ΕΝΗΜΕΡΩΣΗ] Το βίντεο ξεκίνησε...")

#Η κλάση "VideoStream()"  του "imutils.video" module, προετοιμάζει τη ροή βίντεο (video stream) από την προκαθορισμένη
#κάμερα του Raspberry Pi 4. Η επιλογή της κάμερας γίνεται μέσα στις παρενθέσεις του "VideoStream()" όπου δέχεται το όρισμα
#"src = 0". Το "0" σε αυτή την περίπτωση αντιστοιχεί στο camera module V2 που έχει συνδεθεί στο Raspberry. Εάν
#κάποιος θελήσει να χρησιμοποιήσει ροή βίντεο από κάποια άλλη κάμερα που είναι συνδεδεμένη πάνω στο Raspberry, τότε αρκεί
#να επιλέξει τον αριθμό που αντιστοιχεί σε αυτήν την κάμερα. Με την μέθοδο ".start()" ενεργοποιείται η ροή βίντεο και η
#κάμερα ξεκινά να λαμβάνει στιγμιότυπα (Frames).
vs = VideoStream(src = 0).start()

#Αρχικοποίηση της μεταβλητής "fl" με την τιμή "0" για να χρησιμοποιηθεί στο κομμάτι του κώδικα που θα ελέγχει εάν το παράθυρο
#της ροής βίντεο έκλεισε.
fl = 0

#Δημιουργία ατέρμονα βρόγχου επανάληψης "while" αφού κατά τον έλεγχό του δέχεται πάντα την απάντηση της συνθήκης ως "True".
#Μέσα σε αυτόν τον βρόγχο πραγματοποιείται αρχικά σε κάθε επανάληψή του η λήψη ενός στιγμιότυπου "frame" από την κάμερα.
#Έπειτα αυτό προσαρμόζεται στις διαστάσεις που έχουν επιλεχθεί για το παράθυρο στο οποίο θα εμφανιστεί. Έτσι, γίνεται κλήση
#της συνάρτησης "detect_and_predict_mask()" όπου δέχεται αυτό το "frame" και επιστρέφει απαντήσεις σχετικά με το εάν
#ανιχνεύθηκε κάποια μάσκα σε πρόσωπο ή όχι. Έπειτα σε περίπτωση που κάποιο πρόσωπο με μάσκα ή χωρίς ανιχνεύθηκε, ελέγχεται
#και δημιουργείται το νέο "frame" που θα εμφανιστεί στην οθόνη. Αυτό το νέο "frame" θα περιέχει ένα ορθογώνιο παραλληλόγραμμο
#γύρω απο το ανθρώπινο πρόσωπο με χρώμα κόκκινο εάν δεν φοράει μάσκα ή πράσινο εάν φοράει. Επιπλέον, πάνω ακριβώς από αυτό
#το πλαίσιο θα εμφανίζεται κατάλληλο μήνυμα σχετικά με την ύπαρξη ή μη μάσκας, συνοδευόμενο απο την πιθανότητα, σε ποσοστό,
#να είναι σωστή αυτή η πρόβλεψη. Στη συνέχεια γίνεται εμφάνιση αυτού του νέου "frame" στην οθόνη του υπολογιστή μέσα σε
#ένα παράθυρο με διαστάσεις 400x400 και γίνεται έλεγχος εάν ο χρήστης πάτησε το πλήκτρο "ESC" ή το σύμβολο "x" στο πάνω
#δεξιά σημείο του παραθύρου. Εφόσον ένα από τα δύο πατήθηκε, τότε το παράθυρο κλείνει και το πρόγραμμα τερματίζεται. Σε
#περίπτωση που δεν κλέισει το παράθυρο τότε ο κώδικας μέσα στον βρόγχο επανάληψης συνεχίζει να εκτελείται λαμβάνοντας το
#επόμενο στιγμιότυπο.
while True:

#Έλεγχος με τη συνθήκη "if" εάν η μεταβλητή "fl" είναι ίση με το "1". Αυτός ο έλεγχος γίνεται ώστε την πρώτη φορά που
#θα εκτελεστεί ο κώδικας μέσα στον βρόγχο επανάληψης "while", να μην εκτελεστεί το κομμάτι κώδικα μέσα στην συνθήκη "if"
#αυτή. Οπότε αφού έχει οριστεί το "fl" ως "0" έξω απο το "while", αυτή η συνθήκη δεν θα εκτελεστεί την πρώτη φορά.
	if fl == 1:
#Απο τη δεύτερη επανάληψη της εκτέλεσης του κώδικα μέσα στο "while" το παρακάτω κομμάτι κώδικα με τη συνθήκη "if"
#θα ελέγχεται κάθε φορά. Εδώ γίνεται έλεγχος εάν το παράθυρο, που εμφανίζονται τα "frames" ως βίντεο, έκλεισε από
#την επιλογή του χρήστη να πατήσει πάνω στο σύμβολο "x" του παραθύρου. Σε αυτό βοηθάει η εντολή ".getWindowProperty()"
#της βιβλιοθήκης OpenCV η οποία δέχεται σαν πρώτο όρισμα την ονομασία του παραθύρου που θέλει να ελέγξει και σαν
#δεύτερο την εντολή "WND_PROP_VISIBLE" που δείχνει τι θέλουμε να ελέγξουμε. Έτσι, η εντολή ".getWindowProperty()"
#επιστρέφει μία τιμή κάτω του "1" αν το παράθυρο έχει κλείσει ή μεγαλύτερο ή και ίσο με το "1" άν παραμένει ανοικτό.
#Εάν λοιπόν είναι μικρότερο του "1" τότε ο κώδικας μέσα σε αυτό το "if" παραβλέπεται και η εκτέλεση του πορογράμματος
#συνεχίζει παρακάτω. Σε άλλη περίπτωση ο εμφωλευμένος κώδικας εκτελείται.
		if cv2.getWindowProperty("Mask Detection", cv2.WND_PROP_VISIBLE) < 1:

#Εάν εκτελεστεί ο εμφωλευμένος αυτός κώδικας και συγκεκριμένα η εντολή "break", τότε ο κώδικας μέσα στον βρόγχο
#επανάληψης "while" σταματάει να εκτελείται σε αυτό το σημείο και συνεχίζει να εκτελείται από το σημείο που η
#"while" τελειώνει. Η έννοια «τελειώνει» εννοεί ότι ο κώδικας συνεχίζει να εκτελείται μετά την τελευταία εμφωλευμένη
#εντολή που ανήκει στην "while".
			break
#Η "else" συνθήκη θα εκτελεστεί μόνο μία φορά και συγκεκριμένα στην πρώτη επανάληψη του βρόγχου "while" επειδή κατά
#τον έλεγχο του "fl" αυτό θα είναι διάφορο του "1" και συγκεκριμένα "0".
	else:
#Η εντολή που θα εκτελεστεί μία φορά μόνο, είναι η αλλαγή της τιμής της μεταβλητής "fl" απο "0" σε "1", άρα η ενεργοποίηση
#από την επόμενη επανάληψη του βρόγχου "while" του ελέγχου για το κλείσιμο ή μη του παραθύρου που προβάλλει τα "frames".
		fl = 1

#Με την εντολή ".read()" πάνω στο αντικείμενο "vs" λαμβάνεται το στιγμιότυπο της κάμερας εκείνης της δεδομένης στιγμής
#ως εικόνα και αποθηκεύεται στη μεταβλητή "frame".
	frame = vs.read()

#Με την συνάρτηση ".resize()" του module "imutils" αλλάζουν οι διαστάσεις της εικόνας "frame" σε τέτοιες ώστε να είναι
#ευδιάκριτη όταν προβληθεί αργότερα στο παράθυρο εμφάνισης του βίντεο. Το ".resize()" παίρνει ως πρώτο όρισμα το ίδιο
#το "frame" και σαν δεύτερο την διάσταση του νέου πλάτους που θέλουμε να προσαρμοστεί, δηλαδή "width=400". Το ύψος θα
#αλλάξει ανάλογα με το πλάτος, έτσι ώστε η νέα εικόνα να διατηρήσει την αναλογία (aspect ratio) της.
	frame = imutils.resize(frame, width=400)

#Γίνεται κλήση της συνάρτησης "detect_and_predict_mask()" η οποία δέχεται ως ορίσματα το "frame", το μοντέλο ανίχνευσης
#προσώπου (faceNet) και το μοντέλο ανίχνευσης μάσκας (maskNet). Όταν τερματίσει η εκτέλεση της συνάρτησης, αυτή
#επιστρέφει σε μορφή tuple τις λίστες "locs" και "preds" που περιέχουν αντίστοιχα τις συντεταγμένες των νοητών παραλληλογράμων
#γύρω από τα ανθρώπινα πρόσωπα, καθώς και τις προβλέψεις ανίχνευσης ή μη μάσκας.
	(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)

#Δημιουργία βρόγχου επανάληψης "for" που θα ελέγχει κάθε περίπτωση εντοπισμού προσώπου μέσα στο "frame" ξεχωριστά, άρα και
#πρόβλεψη ανίχνευσης ή μη μάσκας σε αυτό, θα εμφανίζει τις απαραίτητες πληροφορίες για αυτά. Ειδικότερα,
#ο εμφωλευμένος κώδικας της "for" θα πλαισιώνει με ένα ορθογώνιο παραλληλόγραμμο συγκεκριμένου χρώματος το ανθρώπινο
#πρόσωπο και θα εμφανίζει πληροφορίες σε μορφή κειμένου για την ύπαρξη ή μη μάσκας και την πιθανότητα της πρόβλεψης
#αυτής σαν ποσοστό. Στην αρχή κάθε επανάληψης του "for" θα αποθηκεύονται στις μεταβλητές "box" και "pred" οι αντίστοιχες
#τιμές απο το "locs" και "preds". Η εντολή "zip()" χρησιμοποιείται πάνω στα "(locs, preds)" έτσι ώστε οι τιμές που θα
#καταχωρούνται από αυτά στα "box" και "pred" να είναι αντιστοιχισμένες μεταξύ τους και να μην μπερδεύονται.
	for (box, pred) in zip(locs, preds):

#Αποθήκευση των τεσσάρων συντεταγμένων που βρίσκονται στο "box" σε τέσσερις επιμέρους μεταβλητές. Οι συντεταγμένες
#"startX" και "startY" αντιπροσωπεύουν την πάνω αριστερή γωνία του παραλληλογράμμου που θα περιέχει ένα ανθρώπινο
#πρόσωπο ενώ οι "endX" και "endY" αντιπροσωπεύουν την κάτω δεξιά γωνία.
		(startX, startY, endX, endY) = box

		#Εναπόθεση των δύο πιθανοτήτων που περιέχει η λίστα "pred[0]" στις μεταβλητές "mask" και "withoutMask". Λόγω του ότι
		#οι πιθανότητες αυτές παράχθηκαν μέσω ενός τανυστή εξόδου, πρέπει το "pred" να «δείχνει» στον δείκτη "0" της λίστας
		#όπου εκεί συγκεκριμένα βρίσκονται αποθηκευμένες οι πιθανότητες που χρειάζονται.
		(mask, withoutMask) = pred[0]

#Έλεγχος με τη συνθήκη "if-else" εάν η πιθανότητα να φοράει το πρόσωπο που εντοπίστηκε μάσκα είναι μεγαλύτερη
#της πιθανότητας να μη φοράει μάσκα. Εάν φοράει τότε δίνεται στη μεταβλητή "label" το string "Mask" αλλιώς δίνεται
#το string "No Mask". Το "label" είναι η μεταβλητή που θα εμφανίσει το αλφαριθμητικό που περιέχει στην οθόνη ως
#κείμενο αργότερα.
		label = "Mask" if mask > withoutMask else "No Mask"

#Έλεγχος του περιεχομένου της μεταβλητής "label" όπου εάν αυτό είναι "Mask" αποθηκεύεται στην μεταβλητή "color"
#το χρώμα πράσινο με τη μορφή BGR (Blue, Green, Red) δηλαδή "(0, 255, 0)". Εάν είναι "No Mask" γίνεται αποθήκευση
#του κόκκινου χρώματος, δηλαδή "(0, 0, 255)". To "color" περιέχει το χρώμα του παραλληλογράμμου που θα σχεδιαστεί
#γύρω από το ανθρώπινο πρόσωπο.
		color = (0, 255, 0) if label == "Mask" else (0, 0, 255)

#Επεξεργασία του ήδη υπάρχοντος "label" και προσθήκη μέσα σε αυτό της πιθανότητας που αντιστοιχεί στο "label" με μορφή
#ποσοστού. Το "{}: {:.2f}%" είναι το string που θα εμφανίζεται στην οθόνη πάνω από κάθε ανθρώπινο πρόσωπο όπου το
#"{}" θα περιέχει το περιεχόμενο του πρώτου ορίσματος της εντολής ".format()" ενώ το "{:.2f}" θα περιέχει το
#περιεχόμενο του δεύτερου ορίσματος με δύο δεκαδικά ψηφία μόνο. Το ".format()" περιέχει ως πρώτο όρισμα την μεταβλητή
#"label" ενώ ως δεύτερο όρισμα την μεγαλύτερη πιθανότητα από τις "mask" και "withoutMask" πολλαπλασιασμένη
#επί "100".
		label = "{}: {:.2f}%".format(label, max(mask, withoutMask) * 100)

#Με την εντολή ".putText()" της βιβλιοθήκης OpenCV εμφανίζεται πάνω στο "frame" το κείμενο που περιέχει το "label".
#Επειδή όμως το κείμενο δεν μπορεί να εμφανιστεί σε οποιοδήποτε σημείο με οποιοδήποτε χρώμα κ.λπ., αυτά όλα ρυθμίζονται
#από τα ορίσματα που δίνονται στο ".putText()". Το πρώτο όρισμα είναι το "frame" στο οποίο θα εμφανιστεί το κείμενο.
#το δεύτερο είναι το κείμενο που θα εμφανιστεί και περιέχεται στο "label". Το τρίτο είναι οι συντεταγμένες που θα
#ξεκινάει το κείμενο δηλαδή "(startX, startY - 10)" που σημαίνει ότι αυτό θα ξεκινάει 10 pixel πιο ψηλά από την
#πάνω αριστερά γωνία του ορθογώνιου παραλληλογράμμου. Το τέταρτο είναι η επιλογή της γραμματοσειράς του κειμένου
#όπου έχει επιλεχθεί να είναι η "FONT_HERSHEY_SIMPLEX". Το πέμπτο είναι το μέγεθος της γραμματοσειράς όπου έχει
#οριστεί στα 0.45. Το έκτο είναι το χρώμα του κειμένου και το έβδομο το πόσο έντονη θα είναι η γραμματοσειρά.
		cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)

#Η εντολή ".rectangle()" της OpenCV λειτουργεί με την ίδια λογική όπως η εντολή ".putText()", απλά σκοπός της είναι
#η εμφάνιση του ορθογώνιου παραλληλογράμου περιγράμματος γύρω από ένα ανθρώπινο πρόσωπο. Εδώ το όρισμα κειμένου
#έχει αφαιρεθεί, αφου δεν υπάρχει, όπως και η γραμματοσειρά μαζί με το μέγεθός της. Παρ' όλα αυτά έχει επιλεχθεί το ίδιο
#χρώμα με το κείμενο και το πόσο έντονες/παχιές θα είναι οι πλευρές του σχήματος.
		cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)

#Αφού το "frame" έχει υποστεί όλες τις απαραίτητες επεξεργασίες και έχουν σχεδιαστεί πάνω του όλα όσα έχει ανιχνεύσει,
#εμφανίζεται στην οθόνη με την εντολή "imshow()" της βιβλιοθήκης OpenCV. Τα ορίσματα της εντολής είναι το όνομα του
#παραθύρου που δημιουργείται και η εικόνα, δηλαδή το "frame", που θα εμφανιστεί μέσα σε αυτό. Επειδή όλος ο κώδικας
#μέσα στον βρόγχο επανάληψης "while" εκτελείται συνεχώς και πολύ γρήγορα, τα frames που εμφανίζονται μέσα στο παράθυρο
#το ένα μετά το άλλο φαίνονται σαν βίντεο και όχι σαν μεμονωμένες εικόνες.
	cv2.imshow("Mask Detection", frame)

#Με την εντολή "waitKey(1)" της βιβλιοθήκης OpenCV το πρόγραμμα περιμένει για ένα millisecond και ελέγχει εάν πατήθηκε
#κάποιο πλήκτρο. Εάν πατήθηκε, τότε η μοναδική δυαδική τιμή που αντιστοιχεί στο συγκεκριμένο πλήκτρο θα υποστεί την λογική
#πράξη AND με τον δυαδικό αριθμό 0xFF (255 στο δεκαδικό). Το αποτέλεσμα αυτής της πράξης θα αποθηκευτεί στην μεταβλητή
#"key". Αυτή η πράξη ουσιαστικά μετατρέπει τον δυαδικό αριθμό σε δεκαδικό μεταξύ του 0 και του 255 και γίνεται για λόγους
#συμβατότητας με άλλες πλατφόρμες.
	key = cv2.waitKey(1) & 0xFF

#Γίνεται έλεγχος μέσω της συνθήκης "if", μεταξύ της τιμής του "key" και του αριθμού "27" που αντιστοιχεί στο πλήκτρο
#"ESC". Εάν οι δύο τιμές είναι ίδιες τότε η εμφωλευμένη εντολή του "if" εκτελείται, αλλιώς ο κώδικας συνεχίζει και o
#βρόγχος επανάληψης "while" ξεκινά από την αρχή.
	if key == 27:

#Εάν η συνθήκη "if" αποδειχθεί αληθής, τότε εκτελείται η εντολή "break" και ο κώδικας μέσα στον βρόγχο
#επανάληψης "while" σταματάει να εκτελείται σε αυτό το σημείο και συνεχίζει να εκτελείται από το επόμενο σημείο έξω
#απο αυτόν τον βρόγχο και συγκεκριμένα με την εντολή "vs.stream.release()".
		break

#Αφού ο χρήστης κλείσει το παράθυρο πληκτρολογώντας το "ESC" ή πατώντας το σύμβολο "X" πάνω δεξιά του παραθύρου, εκτελείται
#η εντολή ".stream.release()" πάνω στο αντικείμενο της ροής βίντεο και την απενεργοποιεί. Έτσι η κάμερα παύει να χρησιμοποιείται.
vs.stream.release()

#Η εντολή ".destroyAllWindows()" της OpenCV κλείνει ό,τι παράθυρο υπάρχει ανοικτό στην μνήμη του υπολογιστή και έπειτα το
#πρόγραμμα τερματίζεται επιτυχώς.
cv2.destroyAllWindows()