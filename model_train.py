import os
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from sklearn.preprocessing import LabelBinarizer
from tensorflow.keras.utils import to_categorical
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.models import Model

# Αρχικοποίηση των μεταβλητών initial learning rate, epochs, batch size και image size. Κάνοντας αλλαγές στις παραμέτρους αυτές,
#μπορούμε να εκπαιδεύσουμε διαφορετικά μοντέλα και να τα συγκρίνουμε ώστε στο τέλος να κρατήσουμε εκείνο με τα καλύ-
#τερα δυνατά αποτελέσματα και το μεγαλύτερο ποσοστό επιτυχίας.
#1)Initial learning Rate(INIT_LR): Είναι μια υπερπαράμετρος που καθορίζει πόσο γρήγορα ή αργά η συνάρτηση βελτιστοποίησης
#του σφάλματος που έχουμε επιλέξει(Adam) κατεβαίνει την καμπύλη σφάλματος. Συνήθως η τιμή της βρίσκεται ανάμεσα στο
#0.0001 and 0.01.
#2)Epochs(EPOCHS): Είναι μια υπερπαράμετρος η οποία ορίζει τον αριθμό των επαναλήψεων που θα χρειαστεί να εκτελεστούν
#για την εκπαίδευση του μοντέλου.
#3)Batch size(BS): Είναι μια υπερπαράμετρος η οποία θέτει τον αριθμό των δεδομένων εκπαίδευσης(trainX, trainY) που
#χρησιμοποιούμε σε μια εποχή(epoch) για να εκπαιδεύσουμε το νευρωνικό δίκτυο. Συνήθως για τα CNN επιλέγεται το 32.
#4)Image size(IMAGE_SIZE): Είναι μια παράμετρος η οποία ορίζει τις νέες διαστάσεις που θα έχουν οι εικόνες για την
#εκπαίδευση του μοντέλου.
INIT_LR = 0.001
EPOCHS = 20
BS = 32
IMAGE_SIZE = 224

#									"""Μέρος 1ο - Preprocessing"""


#Δημιουργία μιας μεταβλητής (string type) με περιεχόμενο τη τοποθεσία των εικόνων
#που θα χρησιμοποιηθούν για την εκπαίδευση του μοντέλου
#dataset_location = r"D:\projects\face_mask_detection\dataset"

dataset_location = r"C:\Users\NitroJin X\Desktop\Διπλωματική 2022- Τσακιρίδης Οδυσσέας\3)CODING\DATASETS\my_custom_only_for_TESTS\dataset"

#Δημιουργία μιας λίστας με 2 περιεχόμενα, το "with_mask" και το "without_mask".
dataset_classes = ["with_mask", "without_mask"]

#Δημιουργία μιας λίστας που αργότερα θα περιέχει όλες τις εικόνες ως αριθμούς και
#πιο συγκεκριμένα ως arrays
data = []

#Δημιουργία μιας λίστας που αργότερα θα περιέχει για κάθε μια απο τις εικόνες της λίστας data
#αντίστοιχα έναν αριθμό ο οποίος θα σημαίνει ή "with_mask" ή "without_mask"
labels = []

#Εκτύπωση μηνύματος στην οθόνη
print("[ΕΝΗΜΕΡΩΣΗ] Η φόρτωση των εικόνων ξεκίνησε...")

#Δημιουργία βρόγχου επανάληψης που την πρώτη φορά το dataset_class = "with_mask"
#και τη δεύτερη/τελευταία φορά θα είναι dataset_class = "without_mask"
for dataset_class in dataset_classes:

	#Δημιουργία μεταβλητής τύπου string η οποία περιέχει το αποτέλεσμα
	#της ένωσης 2 επιμέρους αλφαριθμητικών, του dataset_location και του dataset_class
	#παραδείγματος χάριν:
	#dataset_location = r"D:\projects\face_mask_detection\dataset\"
	#dataset_class = "with_mask"
	#Άρα path = "D:\projects\face_mask_detection\dataset\with_mask"
	path = os.path.join(dataset_location, dataset_class)

	#Δημιουργία βρόγχου επανάληψης που σε κάθε επανάληψή του το περιεχόμενο της μεταβλητής img_name
	#θα είναι η ονομασία μιας απο τις εικόνες του φακέλου που δείχνει το path.
	#Πιο συγκεκριμένα, το os.listdir(path) δημιουργεί μια λίστα με όλες τις ονομασίες
	#των εικόνων που περιέχει ο φάκελος που δείχνει το path
	for img_name in os.listdir(path):
		#Δημιουργία μεταβλητής τύπου string η οποία περιέχει το αποτέλεσμα
		#της ένωσης 2 επιμέρους αλφαριθμητικών, του path και του img_name
		#παραδείγματος χάριν:
		#path = r"D:\projects\face_mask_detection\dataset\with_mask\"
		#img_name = "0_0_21.jpg"
		#Άρα img_path = "D:\projects\face_mask_detection\dataset\with_mask\0_0_21.jpg"
		img_path = os.path.join(path, img_name)

		#Εφόσον το img_path δείχνει στην τοποθεσία του αρχείου μιας συγκεκριμένης εικόνας
		#το load_img φορτώνει στην μεταβλητή image την εικόνα αυτή με τις συγκεκριμένες
		#διαστάσεις που ορίζει το target_size. Άρα με αυτήν την εντολή προσαρμόζουμε όλες
		#τις εικόνες έτσι ώστε να έχουν την ίδια διάσταση με το ίδιο aspect ratio που είχαν
		image = load_img(img_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))

		#Μετατροπή της εικόνας που βρίσκεται στο image σε μορφή πίνακα(array) για να μπορούμε
		#να την επεξεργαστούμε αργότερα πιο εύκολα. Ένα κομμάτι του array αυτού θα έχει για
		#παράδειγμα την παρακάτω μορφή:
		#[84. 58. 45.]
		#[84. 58. 45.]
		#[84. 58. 45.]
		image = img_to_array(image)

		#Επειδή για το CNN model μας θα χρησιμοποιήσουμε την αρχιτεκτονική του μοντέλου
		#mobilenet_v2, χρειάζεται να χρησιμοποιήσουμε την εντολή preprocess_input πάνω
		#στο array της εικόνας μας. Η εντολή αυτή κάνει κάποιες μετατροπές και προσαρμογές
		#στο array έτσι ώστε αυτό να είναι συμβατό κατά την εκπαίδευση του μοντέλου μας.
		#Λαμβάνοντας υπόψιν το παράδειγμα απεικόνισης ενός μέρους του array απο την προηγούμενη
		#εντολή μπορούμε να δούμε την διαφορά του παρακάτω , αφού δηλαδή υποστεί την εντολή του preprocess_input():
		#[-0.34117645 -0.54509807 -0.64705884]
		#[-0.34117645 -0.54509807 -0.64705884]
		#[-0.34117645 -0.54509807 -0.64705884]
		image = preprocess_input(image)

		#Προσθήκη με τη σειρά, όλων των arrays των εικόνων στη λίστα data ώστε να είναι
		#αποθηκευμένες με αυτή τη μορφή σε ένα μέρος που θα μας διευκολύνει στην μετέπειτα
		#επεξεργασία τους
		data.append(image)

		#Για κάθε μια απο τις εικόνες αποθηκεύεται αντίστοιχα και ένα label με την κατάσταση της
		#εικόνας. Είτε δηλαδη "with mask" είτε "without_mask". Όλα τα labels αποθηκεύονται σε μία λίστα
		#όπως και όλες οι εικόνες στην προηγούμενη εντολή για να μπορούν να επεξεργαστούν αργότερα τα δεδομένα
		#με μεγαλύτερη ευκολία
		labels.append(dataset_class)

#Επειδή τα deep learning μοντέλα λειτουργούν σωστά μόνο με arrays, τα labels παρακάτω
#απο λίστα μετατρέπονται και αυτά σε arrays και ειδικότερα τα δεδομένα του που ήταν
#προηγουμένως αλφαριθμητικά, πλέον θα είναι αριθμοί.
#Αρχικά καλείται η κλάση LabelBinarizer() η οποία δημιουργεί το αντικείμενο (object) lb.
#Αυτό γίνεται για να μπορούμε να χρησιμοποιήσουμε τις μεθόδους(class methods) της προαναφερόμενης
#κλάσης πιο εύκολα.
lb = LabelBinarizer()

#Το object lb καλεί την μέθοδο fit_transform πάνω στη λίστα labels και μετατρέπει όλα τα δεδομένα
#της σε 0 και 1. Δηλαδή το αλφαριθμητικό "with_mask" αντικαταστάθηκε με τον αριθμό 0 και το "without_mask"
#με τον αριθμό 1. Επίσης το labels απο λίστα μετατρέπεται σε array (class numpy.ndarray int32) με δεδομένα της μορφής
#[0] ή [1].
labels = lb.fit_transform(labels)

#Η μέθοδος to_categorial χρησιμοποιεί την κωδικοποίηση One-hot encoding η οποία μετατρέπει μια λίστα/array που περιέχει
#κατηγορίες όπως το labels σε μορφή τέτοια που μπορεί να χρησιμοποιηθεί εύκολα από αλγόριθμους μηχανικής
#εκμάθησης (machine learning algorithms).Η βασική ιδέα της κωδικοποίησης αυτής είναι η δημιουργία νέων μεταβλητών που
#λαμβάνουν τις τιμές 0 και 1 για να αντιπροσωπεύουν τις αρχικές κατηγορικές τιμές. Το labels μετά την κωδικοποίηση
#θα περιέχει δεδομένα της μορφής [1. 0.] για "with_mask" ή [0. 1.] για "without_mask" και θα έχει τα εξής χαρακτηριστικά
#(class numpy.ndarray float32)
labels = to_categorical(labels)

#Μετατροπή με τη βοήθεια της βιβλιοθήκης numpy(np) της λίστας data που περιέχει όλα τα array των εικόνων,
#ως ένα array και συγκεκριμένα τύπου float32.
data = np.array(data, dtype="float32")

#Το labels επειδή μετατράπηκε προηγουμένως σε array τύπου float32 δεν χρειάζεται να εκτελέσουμε την εξής ενολή:
#labels = np.array(labels)

#Η μέθοδος train_test_split της βιβλιοθήκης scikit-learn/(sklearn.model_selection) χωρίζει τα δεδομένα των data και
#labels σε 4 arrays 2 κατηγοριών. Ουσιαστικά τα δεδομένα τους θα χωριστούν σύμφωνα με το ποσοστό που ορίζει η ιδιότητα
#test_size όπου στην προκειμένη περίπτωση είναι 0.2 ή αλλιως 20%. Άρα το 20% των δεδομένων θα αποθηκευτεί στα arrays
#testX και testY που αφορούν τη κατηγορία testing και το 80% θα αποθηκευτεί στα trainX και trainY της κατηγορίας
#training. Το X αφορά τα δεδομένα του data και το Y του labels. Τα trainX και trainY θα χρησιμοποιηθούν αργότερα
#για την εκπαίδευση του μοντέλου, το οποίο αφού εκπαιδευτεί θα δοκιμαστεί με τα testX και testY, για την απόδοση, την
#αποτελεσματικότητα και το ποσοστό επιτυχίας του. Η ιδιότητα stratify δείxνει στο array των labels έτσι ώστε ο
#διαχωρισμός των δεδομένων στα trainX, testX, trainY, testY να γίνει με ομοιόμορφη κατανομή και να μην έχουμε
#σφάλματα κατα την εκπαίδευση. Εαν δεν ορίζαμε το stratify ως προς το labels τότε το πρόγραμμα μπορεί να αποθήκευε
#τυχαία στα training arrays μόνο τα δεδομένα που αντιστοιχούν σε labels=[0. 1] και έτσι αργότερα το μοντέλο να έχει
#εκπαιδευτεί μόνο για ανθρώπους που δε φοράνε μάσκες.Η ιδιότητα random_state πέρνει ως όρισμα έναν αριθμό, ο οποίος
#συνήθως είναι το 42. Αυτός ο αριθμός ορίζει την τυχαιότητα που θα χωριστούν τα δεδομένα στα arrays trainX, testX,
#trainY, testY. Αυτή η ιδιότητα βοηθάει έτσι ώστε εαν μελλοντικά θέλουμε να συγκρίνουμε διαφορετικά μοντέλα μεταξύ τους
#να είμαστε σίγουροι ότι τα δεδομένα μας χωρίστηκαν με τον ίδιο τρόπο (λογική τυχαιότητας ν. 42) για την εκπαίδευση
#όλως των υπόλοιπων μοντέλων μας.
(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)


#									"""Μέρος 2ο - Data augmentation"""


#Δημιουργία του αντικειμένου aug απο τη κλάση ImageDataGenerator της βιβλιοθήκης tensorflow.keras.preprocessing.image
#Το ImageDataGenerator() είναι μια κλάση που βοηθάει στην αύξηση των δεδομένων(data augmentation) και συγκεκριμένα
#των εικόνων που θα εκπαιδευτεί το μοντέλο. Το βασικό πλεονέκτημα της αύξησης αυτής είναι πως δεν χρειάζεται να
#αναζητήσει κάποιος χειροκίνητα νέες εικόνες στο διαδίκτυο για να εμπλουτίσει το dataset. Η κλάση αυτή λαμβάνει
#κάθε εικόνα του trainX με τη σειρά κατα την εκπαίδευση του μοντέλου, την αντιγράφει μερικές φορές και επεξεργάζεται
#αυτά τα αντίγραφα της με τέτοιο τρόπο ώστε να φαίνονται σαν να είναι νέες, διαφορετικές εικόνες απο το προτότυπο.
#Έτσι το dataset μας θα έχει μεγαλύτερη ποικιλία εικόνων. Οι επεξεργασίες που θα δεχτούν τα αντίγραφα είναι συγκεκριμένες
#και εξαρτώνται απο τα ορίσματα/ιδιότητες της κλάσης αυτής που θα επιλεχθούν.
#Συγκεκριμένα επιλέχθηκαν:
#1) rotation_range=20: Τυχαία περιστροφή των αντιγράφων ανάμεσα στα όρια των -20 με 20 μοιρών
#2)zoom_range=0.15: Τυχαία εφαρμογή μεγέθυνσης ή σμίκρυνσης στα αντίγραφα. Όταν η τιμή είναι μικρότερη από 1,0, η εικόνα
#σμικρύνεται, με αποτέλεσμα να φαίνεται μικρότερη. Αντίθετα, μια τιμή ζουμ μεγαλύτερη από 1,0 κάνει ζουμ στην εικόνα,
#κάνοντάς τη να φαίνεται μεγαλύτερη. Για παράδειγμα, εάν το εύρος ζουμ έχει οριστεί σε [0,8, 1,2], οι εικόνες μπορούν
#να υποστούν τυχαίο ζουμ μεταξύ 80% και 120% του αρχικού τους μεγέθους, είτε δηλαδή να μικραίνουν είτε να μεγαλώνουν.
#Στην περίπτωσή μας οι εικόνες σμικρύνονται μόνο
#3)width_shift_range=0.2: Τυχαία μετατόπιση των αντιγράφων μέχρι και ένα ποσοστό του πλάτους τους. Απο 0% έως 20% στη
#συγκεκριμένη περίπτωση
#4)height_shift_range=0.2: Τυχαία μετατόπιση των αντιγράφων μέχρι και ένα ποσοστό του ύψους τους. Απο 0% έως 20% στη
#συγκεκριμένη περίπτωση
#5)shear_range=0.15: Τυχαία διαστρέβλωση των αντιγράφων ως προς τον οριζόντιο ή τον κάθετο άξονα. Η γωνία της διαστρέβλωσης
#στη συγκεκριμένη περίπτωση έχει ορισθεί απο -0.15 έως 0.15 ακτίνια(radians) και όχι μοίρες όπως στην παράμετρο rotation_range
#που προαναφέρθηκε.
#6)horizontal_flip=True: Ενεργοποίηση της οριζόντιας τυχαίας αναστροφής των αντιγράφων. Η αναστροφή γίνεται ως προς τον
#κατακόρυφο άξονα όπου η αριστερή μεριά της εικόνας μεταφέρεται δεξιά κια η δεξιά στα αριστερά.Αυτό είναι χρήσιμο εαν σε
#κάποιες εικόνες υπάρχει συμμετρία μεταξύ της πάνω και κάτω μεριάς της εικόνας, οπότε έτσι πετυχαίνουμε να κάνουμε ένα
#αντίγραφο να φαίνεται σαν μια εντελώς διαφορετική εικόνα
#7)fill_mode="nearest": Αυτή η παράμετρος είναι αρκετά σημαντική διότι <<επιδιορθώνει>> τα νέα αντίγραφα που υπέστησαν όλες
#τις αλλαγές που αναφέραμε στις προηγούμενες παραμέτρους. Ειδικότερα, λόγω των μεταμορφώσεων(transformation) τους, τα αντίγραφα
#ενδέχεται να περιέχουν κάποια νέα pixel ή να έχουν δημιουργήσει κενές περιοχές. Η παράμετρος fill_mode τα διορθώνει αυτά,
#με τη μεθοδολογία "nearest" στη συγκεκριμένη περίπτωση, όπου γεμίζει αυτά τα νέα ή κενά pixel με τιμές χρώματος που έχει
#το pixel στην αντίστοιχη θέση της αυθεντικής εικόνας.
aug = ImageDataGenerator(
rotation_range=20,
zoom_range=0.15,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.15,
horizontal_flip=True,
fill_mode="nearest")


#						"""Μέρος 3ο - Κατασκευή του μοντέλου με τη μέθοδο TRANSFER LEARNING """


#Δημιουργία ενός απο τα 2 μέρη του μοντέλου που θα εκπαιδετεί.Το πρώτο αυτό μέρος ονομάζεται βασικό μοντέλο(baseModel)
#και χρησιμοποιεί την αρχιτεκτονική του συνελικτικού νευρωνικού δικτύου MobileNetV2 που έχει ήδη εκπαιδευτεί(pre-trained
# model) στο παρελθόν. Η μεταβλητή baseModel μετατρέπεται σε νευρωνικό δίκτυο άρα και σε αντικείμενο(object) της βιβλιοθήκης
#keras.engine.functional.Functional, με χαρακτηριστικά που δηλώνονται στις παρακάτω ιδιότητες.
#1)weights: Εδώ αρχικοποιούνται τα βάρη του νευρωνικού δικτύου όπου επιλέχθηκαν να είναι ίσα με τα προεκπαιδευμένα (pre-trained)
#βάρη που προέκυψαν απο την εκπαίδευση του MobileNetV2 πάνω στο dataset του Imagenet στο παρελθόν. To Imagenet είναι ένα
#τεράστιο dataset που περιέχει εκκατομύρια labels εικόνων διαφορετικών κατηγοριών. Εκπαιδεύοντας το μοντέλο μας με αυτά
#βάρη, επιτυγχάνετε μείωση του χρόνου εκπαίδευσης και καλύτερα αποτελέσματα αφού αυτά τα βάρη μπορούν να αναγνωρίζουν κάποια
#γενικά οπτικά μοτίβα(general visual patterns) μέσα σε μια εικόνα.
#2)include_top: Με τη boolean τιμή False αφαιρούνται απο την κορυφή του νευρωνικού δικτύου τα πλήρως συνδεδεμένα επίπεδα
#(FC layers) που ήταν υπεύθυνα για τη ταξινόμηση(classification) των τελικών αποτελεσμάτων΄. Αυτά τα FC layers(Fully Connected Layers)
#καταργούνται διότι αργότερα θα προσθέσουμε τα δικά μας FC layers που θα εκπαιδεύσουμε στο headModel και θα ταξινομούν τα δεδομένα
#στις κατηγορίες που θέλουμε εμείς για την συγκεκριμένη εργασία.
#3)input_tensor: Εδώ δηλώνονται οι διαστάσεις των εικόνων του dataset που θα εκπαιδευτεί το μοντέλο καθώς και το είδος των
#εικόνων όπου στην συγκεκριμένη περίπτωση θα είναι έγχρωμες 3 επιπέδων(RGB).
baseModel = MobileNetV2(weights="imagenet", include_top=False, input_tensor=Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))

#Δημιουργία του 2ου μέρους του μοντέλου που θα εκπαιδετεί. Αυτό ονομάζεται headModel, το οποίο αποτελείται κυρίως απο τα
#FC layers που προαναφέρθηκαν και είναι υπεύθυνο για την ταξινόμηση των δεδομένων και την σωστή επιλογή των τελικών αποτελεσμάτων
#(with mask/wothout mask). Αρχικά με την εντολή baseModel.output δηλώνεται ότι η μεταβλητή headModel θα είναι η έξοδος
#του baseModel άρα θα δέχεται τα δεδομένα(εξαγόμενα χαρακτηριστικά μιας εικόνας) που επεξεργάστηκε το baseModel και με τη
#σειρά του θα τα περνάει και αυτό απο επεξεργασία για την τελική τους ταξινόμηση. Πιο συγκεκριμένα αυτό το σύνολο δεδομένων
#που θα δεχτεί το headModel ονομάζεται feature map και έχει τριδιάστατη μορφή 7x7x1280. Το feature map περιέχει πληροφορίες
#για τα χαρακτηριστικά μιας εικόνας. Επίσης τα layers που θα χρησιμοποιηθούν βρίσκονται στο tensorflow.keras.layers.
headModel = baseModel.output

#Ενσωμάτωση του AveragePooling2D layer στο headModel. Αυτό το layer μετατρέπει την μορφή του feature map απο 7x7x1280
#σε 1x1x1280 εαν το pool_size επλιλεχθεί (7,7). Αυτός ο μετασχηματισμός δέχεται κάθε κανάλι(channel) του 7x7x1280 με τη σειρά
#και απο 49(7x7) pixel το αλλάζει σε 1(1x1). Συγκεκριμένα υπολογίζεται ο μέσος όρος των τιμών που περιέχουν τα 49 pixel
#και αυτός αποθηκεύεται στη νέα μορφή του feature map. Κάποια απο τα πλεονέκτημα αυτής της διαδικασίας είναι η μείωση των
#χωρικών διαστάσεων spatial dimensions,η μείωση του θορύβου και η βελτίωση της υπολογιστικής απόδοσης.
headModel = AveragePooling2D(pool_size=(7, 7))(headModel)

#Ενσωμάτωση του Flatten στο headModel. Το layer αυτό δέχεται το αποτέλεσμα του AveragePooling2D καλώντας δίπλα απο την εντολή
#Flatten(name="flatten") το (headModel). Συγκεκριμένα δέχεται το feature map της μορφής 1x1x1280 το οποίο έχει 1280 κανάλια
#και το μετατρέπει σε ένα διάνυσμα(vector) μιας μόνο διάστασης δηλαδή 1x1280. Αυτή η διαδικασία κυρίως βοηθάει στη συμβατότητα
#αφού απο το επόμενο βήμα που θα ακολουθήσουν τα FC layers αυτά θα δεχτούν ως inputs το feature map που θα πρέπει να έχει
#τη μορφή μονοδιάστατου διανύσματος. Ειδικότερα το Flatten layer παίζει κρίσιμο ρόλο στη μετάβαση από τa CNN επίπεδα στα
#FC επίπεδα των νευρωνικών δικτύων. Ακόμα, κάθε στοιχείο του διανύσματος πλέον θεωρείται ως ένας νευρώνας, άρα το FC layers
#θα δεχτεί 1280 τιμές ως εισόδους σε κάθε νευρώνα που περιέχει το επόμενο layer.
headModel = Flatten(name="flatten")(headModel)

#Δημιουργία ενός FC layer. Το Dense δέχεται ως είσοδο τις 1280 τιμές του διανύσματος που δημιούργησε το Flatten αναγνωρίζοντάς
#τις ως αρχικούς νευρώνες και δημιουργεί ένα FC layer που αποτελείται απο 128 νέους νευρώνες. Κάθε νέος νευρώνας απο τους
#128 δέχεται την τιμή που περιέχει κάθε νευρώνας απο τους 1280 την οποία πολλαπλασιάζει με τυχαία βάρη(weights) αφου αυτά
#θα πάρουν τις τελικές τους σωστές τιμές μετά την εκπαίδευση του τελικού μοντέλου. Στη συνέχεια όλα αυτά τα σύνολα
#γινομένων προσθέτονται μεταξύ τους και δίνουν μια τιμή ως αποτέλεσμα η οποία είναι πιθανόν να έχει αρνητική τιμή πέρα απο
#μηδενική ή θετική.Επιπλέον, στο προηγούμενο άθροισμα μπορεί να προστεθεί και μια τιμή που ονομάζεται πόλωση(bias) που
#επίσης θα αλλάξει με την εκπαίδευση. Επειδή οι τιμές θέλουμε να ειναι θετικές χρησιμοποιήται η συνάρτηση ενεργοποίησης Rectified Linear Units
#(Relu) η οποία ανιχνεύθει την τιμή που έχει ο νέος νευρώνας και εαν αυτή είναι αρνητική την μετατρέπει σε μηδέν. Σε κάθε
#άλλη περίπτωση η τιμή παραμένει ίδια.
headModel = Dense(128, activation="relu")(headModel)

#Εφαρμογή του Dropout στις τιμές που παρήγαγαν οι νευρώνες του προηγούμενου layer. Το dropout είναι μια τεχνική τακτοποίησης
#(regularization technique) που απορρίπτει τυχαία το 50% των εξόδων των νευρώνων από το προηγούμενο layer κατά τη διάρκεια
#της εκπαίδευσης του τελικού μοντέλου.Αυτό βοηθά στην αποφυγή της υπερεκπαίδευσης(overfitting) που είναι η κατάσταση στην οποία
#το μοντέλο έχει καταφέρει να εκπαιδευτεί πολύ καλά πάνω στo dataset που ορίστηκε για την εκπαίδευση του με αποτέλεσμα να μην
#ανταποκρίνεται σωστά σε άλλα δεδομένα που του δίνονται. Πιο συγκεκριμένα με το Dropout γίνεται αποφυγή της υπερεκπαίδευσης
#κάνοντας το δίκτυο να μη βασίζεται μόνο σε συγκεκριμένους νευρώνες αλλά να εκαπιδεύεται με πιο γενικευμένα χαρακτηριστικά
#(generalized features).
headModel = Dropout(0.5)(headModel)

#Δημιουργία του δεύτερου και τελευταίου FC layer. Το Dense αυτη τη φορά δέχεται στην είσοδό του τις εξόδους του προηγούμενου
#FC layer με τους 128 νευρώνες των οποίων οι μισές τιμές θα είναι πλέον μηδενικές λόγω του Dropout. Το Dense εδώ δημιουργεί
#τους 2 τελικούς νευρώνες του δικτύου και αναλόγως τη τιμή τους το μοντέλο θα έχει πάρει την τελική απόφαση, δηλαδή εαν η
#εικόνα που επεξεργάστηκε ανήκει στην κατηγορία with mask ή without mask. Όπως και στο προηγούμενο FC layer έτσι και εδώ
#κάθε ένας απο τους 2 νευρώνες θα λαμβάνει στην είσοδό του όλες τις εξόδους των προηγούμενων 128 νευρώνων. Αυτές οι τιμές
#θα πολλαπλασιάζονται και εδώ με κάποια βάρη και έπειτα υπολογίζεται το άθροισμα όλων αυτών των γινομένων και ενδεχομένως
#η πρόσθεση σε αυτό το άθροισμα μιας τιμής του bias. Έτσι οι 2 νευρώνες θα έχουν απο μια τιμή ο καθένας η οποία επειδή
#μπορεί να είναι μεγαλύτερη του 1 θα πρέπει να την μετατρέψουμε σε τιμή πιθανότητας δηλαδή ανάμεσα στο 0 και το 1. Αυτό
#το επιτυγχάνουμε με την συνάρτηση ενεργοποίησης softmax η οποία προσαρμόζει τις τιμές στο πεδίο που θέλουμε[0-1]. Η
#πιθανότητα αυτή θα είναι το τελικό αποτέλεσμα που θα κρίνει το μοντέλο εαν κατάφερε να αναγνωρίσει την κατάσταση της εικόνας
#που δέχτηκε σαν είσοδο κατα την εκπαίδευση και ποια είναι η πιθανότητα/το ποσοστό που το κατάφερε. Αναλόγως την πιθανότητα
#και το ποσοστό επιτυχίας του το νευρωνικό δίκτυο ενημερώνει τα βάρη του και τα bias με σκοπό να μειώσει όσο περισσότερο
#μπορεί το ποσοστό λάθους.
headModel = Dense(2, activation="softmax")(headModel)

#Παρακάτω φαίνονται αναλυτικά όλα τα layers του headModel και τα χαρακτηριστικά τους:
# KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 1280), dtype=tf.float32, name=None), name='out_relu/Relu6:0', description="created by layer 'out_relu'")
# KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1280), dtype=tf.float32, name=None), name='average_pooling2d/AvgPool:0', description="created by layer 'average_pooling2d'")
# KerasTensor(type_spec=TensorSpec(shape=(None, 1280), dtype=tf.float32, name=None), name='flatten/Reshape:0', description="created by layer 'flatten'")
# KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dense/Relu:0', description="created by layer 'dense'")
# KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dropout/Identity:0', description="created by layer 'dropout'")
# KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='dense_1/Softmax:0', description="created by layer 'dense_1'")

#Ενοποίηση των 2 επιμέρους νευρωνικών δικτύων που δημιουργήθηκαν σε 1(model), δηλαδή του baseModel που είναι το CNN για την δημιουργία
#feature map απο τις εικόνες του training dataset και του headModel που περιέχει τα FC layers τα οποία είναι υπεύθυνα
#για την ταξινόμηση του feature map στις κατηγορίες mask ή without mask. Μετά την σύνδεση του headModel στην κορυφή του
#baseModel το ολοκληρωμένο νευρωνικό δίκτυο που θα εκπαιδεύσουμε θα έχει την ονομασία model. Η ένωση επιτυγχάνεται με την
#εντολή Model() που βρίσκεται στο tensorflow.keras.models.
model = Model(inputs=baseModel.input, outputs=headModel)

#Απενεργοποίηση της δυνατότητας εκπαίδευσης όλων των layers του baseModel αφού είναι ήδη εκπαιδευμένο και δεν θέλουμε να
#υποστεί κάποια αλλαγή στα βάρη ή γενικότερα στις παραμέτρους του. Αντίθετα το headModel είναι αυτό που θα εκπαιδευτεί
#εξ ολοκλήρου και απο την αρχή γιατί εκείνο αφορά την ταξινόμηση στις 2 κλάσεις που επιθυμούμε για αυτό το project.
for layer in baseModel.layers:
	layer.trainable = False



#print(model)